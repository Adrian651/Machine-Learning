{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linear_svc', LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "# matplotlib is a plotting library which produces publication \n",
    "#quality figures in a variety of hardcopy formats and interactive \n",
    "#environments across platforms. \n",
    "\n",
    "import matplotlib as plt #Testing out MatPlotLib\n",
    "from sklearn import datasets #Using SkLearn \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
    "y = (iris[\"target\"] == 2).astype(np.float64)  # Iris-Virginica\n",
    "\n",
    "#Pipline is just an abstract notion, it's not some existing ml algorithm. \n",
    "#Often in ML tasks you need to perform sequence of different transformations \n",
    "#of raw dataset before applying final estimator.\n",
    "svm_clf = Pipeline((\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\")),\n",
    "    ))\n",
    "\n",
    "svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
      "          37.88      , -122.23      ],\n",
      "       [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
      "          37.86      , -122.22      ],\n",
      "       [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
      "          37.85      , -122.24      ],\n",
      "       ..., \n",
      "       [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
      "          39.43      , -121.22      ],\n",
      "       [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
      "          39.43      , -121.32      ],\n",
      "       [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
      "          39.37      , -121.24      ]]), 'feature_names': ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude'], 'DESCR': 'California housing dataset.\\n\\nThe original database is available from StatLib\\n\\n    http://lib.stat.cmu.edu/datasets/\\n\\nThe data contains 20,640 observations on 9 variables.\\n\\nThis dataset contains the average house value as target variable\\nand the following input variables (features): average income,\\nhousing average age, average rooms, average bedrooms, population,\\naverage occupation, latitude, and longitude in that order.\\n\\nReferences\\n----------\\n\\nPace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\nStatistics and Probability Letters, 33 (1997) 291-297.\\n\\n', 'target': array([ 4.526,  3.585,  3.521, ...,  0.923,  0.847,  0.894])}\n",
      "\n",
      " housing.head()\n",
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  \n",
      "0    -122.23  \n",
      "1    -122.22  \n",
      "2    -122.24  \n",
      "3    -122.25  \n",
      "4    -122.25  \n",
      "\n",
      " housing.info()\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 8 columns):\n",
      "MedInc        20640 non-null float64\n",
      "HouseAge      20640 non-null float64\n",
      "AveRooms      20640 non-null float64\n",
      "AveBedrms     20640 non-null float64\n",
      "Population    20640 non-null float64\n",
      "AveOccup      20640 non-null float64\n",
      "Latitude      20640 non-null float64\n",
      "Longitude     20640 non-null float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 1.3 MB\n",
      "None\n",
      "\n",
      " housing.describe()\n",
      "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
      "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
      "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
      "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
      "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
      "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
      "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
      "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
      "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
      "\n",
      "           AveOccup      Latitude     Longitude  \n",
      "count  20640.000000  20640.000000  20640.000000  \n",
      "mean       3.070655     35.631861   -119.569704  \n",
      "std       10.386050      2.135952      2.003532  \n",
      "min        0.692308     32.540000   -124.350000  \n",
      "25%        2.429741     33.930000   -121.800000  \n",
      "50%        2.818116     34.260000   -118.490000  \n",
      "75%        3.282261     37.710000   -118.010000  \n",
      "max     1243.333333     41.950000   -114.310000  \n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.datasets\n",
    "# pandas is a software library written in python \n",
    "#for data manipulation and analysis. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "housingData = sklearn.datasets.fetch_california_housing()\n",
    "print housingData\n",
    "housing = pd.DataFrame(housingData.data, columns=housingData.feature_names)\n",
    "print \"\\n housing.head()\\n\", housing.head()\n",
    "print \"\\n housing.info()\\n\", housing.info()\n",
    "print \"\\n housing.describe()\\n\", housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 75 75\n",
      "Training Results: 1.0\n",
      "Test Results: 0.906666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#The Iris library implements a data model to create a data \n",
    "#abstraction layer which isolates analysis and visualisation \n",
    "#code from data format specifics. The data model we have chosen \n",
    "#is the CF Data Model\n",
    "iris = load_iris()\n",
    "Y = iris.target\n",
    "X = iris.data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=42)\n",
    "\n",
    "print len(X), len(x_train), len(x_test)\n",
    "\n",
    "classifier = DecisionTreeClassifier(max_depth=15)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_train)\n",
    "n_correct = sum(y_pred == y_train)\n",
    "print \"Training Results:\",  n_correct / len(y_train)\n",
    "\n",
    "y_pred = classifier.predict(x_test)\n",
    "n_correct = sum(y_pred == y_test)\n",
    "print \"Test Results:\", n_correct / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
